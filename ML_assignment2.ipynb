{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_assignment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFeFTJA41KCb",
        "colab_type": "text"
      },
      "source": [
        "# **1.Introduction**\n",
        "Flowers have important ornamental and economic value. However, there are many kinds of flowers and many kinds of flower petals. At present, the identification and management of flower patterns are mainly carried out manually, which is not efficient and is prone to errors for ordinary non-professionals. On the other hand, image recognition applications and related theoretical research are developing rapidly, and intelligent recognition of images has become one of the most important development and application goals in the field of artificial intelligence.\n",
        " \n",
        "Classification is the most famous problem in identifying image categories in computer vision, and it is also the basis for other tasks such as target detection, behavior tracking, and image segmentation. The application of image classification covers transportation, security, medical, government, Internet and other fields. Its application scenarios include traffic scene recognition, face detection, intelligent video analysis, and medical image recognition.\n",
        " \n",
        "In recent years, the Convolutional Neural Network (CNN) has achieved amazing results in the field of image recognition. CNN takes the image pixel information as input, extracts and abstracts the feature through convolution, and directly outputs the image recognition result. This method retains the original image information to a great extent, and the end-to-end learning method has achieved good results.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeZhCLgP1JY8",
        "colab_type": "text"
      },
      "source": [
        "# **2.Dataset**\n",
        "The dataset we use is the 17flowers dataset. In flower dataset, there are 17 classes with 680 images in train dataset, 340 images in test dataset and 340 images in validation dataset. It must be mentioned that there are only 660 pictures in train2 data, and the other eight data sets all fit what I said above. \n",
        "\n",
        "Among them, the training set is used to train the model; the validation set is used to make the model selection; the test set is used to evaluate the selected model.\n",
        "\n",
        "Before the model is trained, we must choose the model to be trained. After selecting the model, we will start training. The goal of training is to determine the parameters of the model. Training is usually done by designing the loss function and then optimizing the loss function. In most cases, we don't know which model is suitable, so we often need to train a variety of models. After training, we will get the results of multiple models. We hope to choose the most suitable ones from these trained models. model. We test all models by using the validation set and then select the one with the lowest error rate.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67V4teOs1Jh9",
        "colab_type": "text"
      },
      "source": [
        "# **3.Methodology**\n",
        "Convolutional neural network (CNN) is a special deep neural network model. Its particularity is embodied in two aspects. On the one hand, its connections between neurons are not fully connected, on the other hand, some of the same layer The weight of the connections between neurons is shared. Its network structure of non-full connection and weight sharing makes it more similar to biological neural networks, reducing the complexity of the network model and reducing the number of weights.\n",
        "We used three CNN models to train and test separately, namely VGG16, GoogleNet, and Alexnet.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bp0Sd841Jlx",
        "colab_type": "text"
      },
      "source": [
        "## **3.1 AlexNet**\n",
        "The baseline architecture that we used is AlexNet model which is a classic model for CNN. The following figure 6 is the network structure of Alex-Net, including five convolutional layers and three full connection layers. It can be seen that the framework is divided into upper and lower branches, which aims to facilitate parallel training using GPU at the same time. At the third layer of convolution and full connection, the upper and lower branches can interact with each other. \n",
        "\n",
        "In the customized architecture, we use 4 convolutional layer, 5 pooling layer, 2 dropout layer, 1 flatten layer, 2 dense layer.\n",
        "\n",
        "The convolutional layer is the basic operation layer in the convolutional neural network. Convolution is a local operation in which a certain size of convolution kernel is applied to a local image region to obtain the local information of the image. The parameters of the convolution kernel in the convolution network are learned through network training. we are going to use a little convolution kernel of 3 * 3. \n",
        "The pooling layer contains no parameters to learn. When pooling is set, only the average or Max, kernel size and stride parameters of the pooling operation should be specified. The introduction of pooling layer is to reduce and abstract the visual input object according to the human visual system. The kernel size of the pooling layer is generally set as 2 * 2. \n",
        "Activation function layer is also called nonlinear mapping layer. In other words, the activation function is introduced to increase the expressiveness of the entire network. Otherwise, the stack of several linear operation layers can only play the role of linear mapping, and complex functions cannot be formed. Intuitively, the activation function simulates the properties of biological neurons, which receive a set of input signals and produce output. I both use Relu and Sigmoid activation function in my model. After the Sigmoid function, the range of output response is compressed to between [0, 1], but for the area on both sides of the function, this part of output will be compressed to 1 or 0. Such treatment may bring about gradient saturation effect. Gradient saturation can be avoided by using the relu function, and the relu function is easier to compute.\n",
        "The Flatten layer is used to one-dimensional the multidimensional input for the transition from the convolution layer to the Dense. Dropout is to randomly drop some weight of the current layer, reduce the complexity of the model, enhance the generalization ability of the model and prevent overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcFMf-hW1JpG",
        "colab_type": "text"
      },
      "source": [
        "## **3.2 VGG16**\n",
        "VGG is an exploration of deep network nerves. VGGNet repeatedly stacks 3x3 small convolution kernels and 2x2 maximum VGG was proposed by the Visual Geometry Group of Oxford, hence the name VGG. \n",
        "The model participated in the 2014 ImageNet Image Classification and Positioning Challenge and achieved excellent results: ranked second in the classification task and ranked first in the positioning task. This network is related to ILSVRC 2014. The main job is to prove that increasing network depth can affect the final performance of the network to some extent.\n",
        "\n",
        "VGG is an exploration of deep network nerves. VGGNet repeatedly stacks 3x3 small convolution kernels and 2x2 maximum pooling layers, and successfully constructs 16~19 layers of deep convolutional neural networks.\n",
        "In the test, the network is first converted into a full convolution network. The first fully connected layer is converted into a 7×7 convolution layer, and the latter two fully connected layers are converted into a 1×1 convolution layer. The result is an N×N×M result, which is called a class score map, where M is equal to the number of categories, and the size of N depends on the input image size Q. When calculating the final score of each category, N×N The values above are averaged, and the result of 1 × 1 × M is obtained. This result is the final category score. This method is called intensive evaluation. This replacement of the fully connected layer is equivalent to applying the fully connected layer to the entire uncut image, and getting a score graph of a category whose number of channels is equal to the number of categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_Ykkt9M1Jsk",
        "colab_type": "text"
      },
      "source": [
        "## **3.3 GoogleNet**\n",
        "GoogleNet, first appeared in 2014, has deeper layers and much more accuracy and less computing than previous method like AlexNet. The main theory of it is using 1x1 convolution to reduce and increase the dimension. The baseline used here is inceptionV3. After did some research on the Internet, we were acknowledged that the architecture should suit dataset class. The original GoogleNet in articles is for large dataset and has too many layers. \n",
        "\n",
        "The modified architecture freezes some layers to have a faster training, retain the convolution layer of GoogleNet, add fully connected layer to have a better accuracy for Flower Dataset. Since the original model of GoogleNet is hard to use, my first thought was to adapt a similar back propagation neural network with original GoogleNet features as a modified work, but it was so hard that time. We used fully connected layer in GoogleNet although it is not originally included.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_pYbuBJ1Jvq",
        "colab_type": "text"
      },
      "source": [
        "# **4.Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ7-YUk21Jxv",
        "colab_type": "text"
      },
      "source": [
        "## **4.1 AlexNet**\n",
        "As shown, when we use the same set of validation data and training model, the first plot is the result of the first run, and the second plot is the result of selecting the best result of graph a. As a weight. Obviously, the accuracy of Figure 13 is higher than the accuracy of Figure 12.\n",
        "\n",
        "When training a model, it often leads to over-fitting of the model. This is most likely caused by two factors. First, there may be situations where the training data is insufficient, which means that the training data cannot estimate the distribution of the entire data. The second is the overtraining model. I think this may be because the data in the flower dataset is insufficient because the training set has 680 images and the test has 340 images. Often, the most common methods to prevent overfitting are: early stop, data expansion, regularization, and dropout."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AodDIdy04zQm",
        "colab_type": "text"
      },
      "source": [
        "## **4.2 VGG16**\n",
        "The structure of VGGNet is very simple. The entire network uses the same size convolution kernel size (3 × 3) and maximum pool size (2 × 2), several small filter (3 × 3) convolution layer combination ratio large filter Concentrator (5 × 5 7 × 7 or) convolutional layer: It has been proven that performance can be improved by continuously deepening the network structure.\n",
        "However, VGG consumes more computing resources and uses more parameters (not 3x3 convolution errors), resulting in more memory usage. Most of the parameters come from the first fully connected layer, and VGG has three fully connected layers.\n",
        "These figures below show the model accuracy of the VGG model. The first two graphs are not added with the Dropout layer. It can be seen that the accuracy of the test is about 80%. However, after adding the Dropout layer, the accuracy of the test is significantly improved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1C5R3Ql45KC",
        "colab_type": "text"
      },
      "source": [
        "## **4.3 GoogleNet**\n",
        "In the process we found that the training fluctuate a lot around epoch 20 and 30 while the model in 25th epoch is the best according to validation. We choose it and conclude the analysis. The cowslip and tulip is a little hard for this model to recognize, especially the cowslip. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JncMpniB5DCK",
        "colab_type": "text"
      },
      "source": [
        "# **5.Ethical**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eio5v1DG5JS6",
        "colab_type": "text"
      },
      "source": [
        "# **6.Conclusion**"
      ]
    }
  ]
}